\documentclass[11pt,a4paper]{article}
\usepackage{amssymb,amsfonts,amsmath,calc,tikz,pgfplots,geometry,mathtools}
\usepackage{color}   %May be necessary if you want to color links
\usepackage{hyperref}
\usepackage{amsthm}
\usepackage{fancyhdr}
\pagestyle{fancy}
\usetikzlibrary{positioning}
\geometry{margin=1in}
\pgfplotsset{compat=1.18}
\setlength{\headheight}{14.6pt}
\addtolength{\topmargin}{-1.6pt}
\hypersetup{
    colorlinks=false, %set true if you want colored links
    linktoc=all,   %set to all if you want both sections and subsections linked
    linkcolor=black,  %choose some color if you want links to stand out
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{remark}{Remark}[section]
\newtheorem{example}{Example}[section]
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{paradox}{Paradox}[section]

\DeclareMathOperator{\lcm}{lcm}
\DeclareMathOperator{\supp}{supp}
\DeclareMathOperator{\idealin}{\triangleleft}
\DeclareMathOperator{\im}{im}
\DeclareMathOperator{\Aut}{Aut}
\DeclareMathOperator{\End}{End}
\DeclareMathOperator{\Inn}{Inn}
\DeclareMathOperator{\Out}{Out}
\DeclareMathOperator{\Mat}{Mat}
\DeclareMathOperator{\std}{std}
\DeclareMathOperator{\Int}{Int}
\DeclareMathOperator{\diam}{diam}
\DeclareMathOperator{\Bin}{Bin}
\DeclareMathOperator{\Geo}{Geo}
\DeclareMathOperator{\Poi}{Poi}

\newcommand{\N}{\mathbb{N}}
\newcommand{\st}{\text{ s.t. }}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\F}{\mathbb{F}}
\newcommand{\Omicron}{O}
\newcommand{\ip}[2]{\langle #1, #2 \rangle}
\newcommand{\set}[2]{ \left\{ #1 \mid #2 \right\} }
\newcommand{\abs}[1]{\left\lvert #1\right\rvert}
\newcommand{\norm}[1]{\left\lVert #1\right\rVert}
\renewcommand{\tt}[1]{\textnormal{\textbf{(#1).}}} %tt=theorem title
\newcommand{\bigslant}[2]
{{\raisebox{.2em}{$#1$}\left/\raisebox{-.2em}{$#2$}\right.}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{\textbf{Introduction to Probability Theory}}
\author{}
\date{}
\begin{document}
	\maketitle
	\newpage
  \section{Probability Spaces}
  Before diving in into the definition of a probability space, the main object
  of this course, we must note that this course is an introductory course in 
  probability theory, which means we don't have the tools from measure theory
  to formalize probability. Thus, some proofs will be omitted, and we will
  also need to formalize discrete and continuous probability theory seperately.

  First, let us introduce a paradox.
  \begin{paradox}
    \tt{Bertrand's Paradox}
    Consider an equilateral triangle inscribed in a circle. 
    Suppose a chord of the circle is chosen at random. 
    What is the probability that the chord is longer than a side of the 
    triangle? 
  \end{paradox}

  We can ponder about this paradox for a while, but Bertrand himself came up
  with three solutions, each with a different answer. The main difference in
  his methods lies in the way in which we choose the chords.

  \begin{definition}
    The sample space of an experiment, is a set $\Omega$ which contains all
    the possible outcomes of the experiment.
  \end{definition}

  A good thing to note, is that we can choose different sample spaces for the
  same experiment. For example, if the experiment consists of rolling two
  dice, and we want to check for the sum of the results, we can set either
  $\Omega = \{1,2,3,4,5,6\}^2$, for the result of each dice, or 
  $\Omega = \{1,2,\dots,11,12\}$ for the sum of the results of the dice. 

  \begin{definition}[Probability space, intuitive definition]
    A discrete probability space is a pair $(\Omega, \mathbf P)$, where
    $\Omega$ is a countable sample set, and $\mathbf P \colon \Omega \to 
    [0,1]$ is a function such that 
    $\sum_{\omega \in \Omega}{\mathbf P(\omega)} = 1$. 
    Intuitively, we say that $\mathbf P(\omega)$ represents the probability
    that $\omega$ will happen.
  \end{definition}
  \begin{definition}
    A subset of the sample space $A \subseteq \Omega$ is called an event.
    We also define:
    \[
      \mathbf P(A) := \sum_{\omega \in \Omega}{\mathbf P(\omega)}
    \]
  \end{definition}
  
  Here are a few properties of probability functions we can immediately 
  verify:
  \begin{enumerate}
    \item $\mathbf P(\Omega) = 1$
    \item $\mathbf P(\emptyset) = 0$
    \item For $A \subset \Omega$ we have $\mathbf P(A^c) = 1 - \mathbf P(A)$
    \item If $\{A_n\}_{n=1}^{N}$ are disjoint sets then 
      \[
        \mathbf P\left(\cup_{n=1}^{n}{A_n}\right) = 
        \sum_{n=1}^{N}{\mathbf P(A_n)}.
      \]
    \item If $\{A_n\}_{n=1}^{\infty}$ is a sequence of pairwise disjoint sets 
      then
      \[
        \mathbf P\left(\cup_{n=1}^{\infty}{A_n}\right) = 
        \sum_{n=1}^{\infty}{\mathbf P(A_n)}.
      \]
  \end{enumerate}

  In a finite probability space we say that the probability function is
  continuous if for every $\omega \in \Omega$ we have 
  $\mathbf P(\omega) = \frac{1}{|\Omega|}$.

  We now proceed to consider an experiment in which we choose a direction in
  $\R^2$ at random, on $S^1$ and write it. The sample space is:
  \[
    \Omega = S^1 = \set{e^{i \theta}}{\theta \in [0,2 \pi)}.
  \]
  A natural question to ask, is if we can define a uniform probability function
  in the sense that for any arc $[a,b] \subset S^1$ we have 
  $\mathbf P([a,b]) = b - a$. The answer is that with the definition we have
  worked with so far, we can't. We see that $\mathbf P(\{a\}) = 0$ for 
  any $a \in S^1$, and thus we have that
  \[
    \mathbf P(\Omega) = \sum_{\omega \in \Omega}{\mathbf P(\omega)} = 0.
  \]
  To solve this problem, we may try to define a new function $\mathbf P \colon 
  2^\Omega \to [0,1]$ that will directly assign each event its probability,
  but unfortunately for us, such a function, that satisfies the desired
  properties of a probability function, does not exist. The proof for this
  is in the course ``real valued function'', and will not be discussed here.
  However, we can give a proof, under the assumption of the following lemma.

  \begin{lemma}
    Exists a set $E \subset S^1$ such that for any rational number 
    $q \in (0, 2 \pi) \cap \Q$ we have $e^{i q}E \cap E = \emptyset$.
  \end{lemma}

  Indeed we see that

  \[
    1 = \mathbf P(\Omega) = 
    \mathbf P\left({\bigcup_{q \in [0,2\pi] \cap \Q}}{e^{i q} E}\right) = 
    \sum_{q \in [0,2\pi) \cap \Q}{\mathbf P(e^{i q} E)} = 
    \sum_{q \in [0,2\pi) \cap \Q}{\mathbf P(E)}
  \]

  And now we have a contradiction because if we set $\mathbf P(E) = a$ then
  we get
  \[ 1 = \sum_{q \in [0,2\pi) \cap \Q}{a} \]
  and this equation has no solution.

  The classical solution to this problem, is to only define the probability
  function only on certain subsets of the sample space. Suppose we denote
  this new domain as $\mathcal F \in 2^\Omega$. In order for the desired
  properties to hold we must also accept that $\mathcal F$ holds certain
  conditions.

  \begin{definition}[$\sigma$-algebra]
    Let $\Omega$ be a set.\ We say that $\mathcal F \subset 2^\Omega$ is a
    $\sigma$-algebra (sometimes called a $\sigma$-field) of sets, if it
    satisfies the following properties:
    \begin{enumerate}
      \item $\Omega \in \mathcal F$.
      \item If $A \in \mathcal F$ then $A^c \in \mathcal F$.
      \item If $(A_n)_{n=1}^{\infty} \subset \mathcal F$, then
        $\cup_{n=1}^{\infty}{A_n} \in \mathcal F$.
    \end{enumerate}
  \end{definition}

  We can now formally define a probability space.

  \begin{definition}[Probability Space]
    A probability space is a triplet $(\Omega, \mathcal F, \mathbf P)$ such
    that $\Omega$ is a set, $\mathcal F$ is a $\sigma$-algebra of $\Omega$,
    and $\mathbf P \colon \mathcal \to [0,1]$ is a probability function that
    satisfies:
    \begin{enumerate}
      \item $\mathbf P(\Omega) = 1$
      \item If $(A_n)_{n=1}^{\infty} \subset \mathcal F$ are disjoint, then
        $\mathbf P\left(\cup_{n=1}^{\infty}{A_n}\right) = 
        \sum_{n=1}^{\infty}{\mathbf P(A_n)}$.
    \end{enumerate}
  \end{definition}

  In this case we shall call elements of $\mathcal F$ events.

  \begin{proposition}
    Exists a $\sigma$-algebra $\mathfrak B$ of $\Omega = S^1$, and a unique
    function $\mathbf P \colon \mathfrak \to [0,1]$ such that 
    $(\Omega, \mathfrak B, \mathbf P)$ is a probability space and $\mathbf P$
    is invariant to spinning on the sphere.
  \end{proposition}

  \begin{definition}[Algebra of Sets]
    A set $\mathcal C \subset 2^\Omega$ is called an algebra of sets if it 
    satisfies the following properties:
    \begin{enumerate}
      \item $\Omega \in \mathcal C$.
      \item If $A \in \mathcal C$, then $A^c \in \mathcal C$.
      \item if $A,B \in \mathcal C$, then $A \cup B \in \mathcal C$.
    \end{enumerate}
  \end{definition}

  We can immediately verify that any algebra $\mathcal C$ is closed under
  finite unions and finite intersections. We also notice that 
  $\emptyset \in \mathcal C$, and that if $A,B \in \mathcal C$, then
  $A \setminus B \in \mathcal C$. We can also notice that any 
  $\sigma$-algebra is closed under countable intersections, and that
  every $\sigma$-algebra is in particular also an algebra.

  \begin{example}
    If $\Omega$ is a set, and $A \subset \Omega$, then both $2^\Omega$ and 
    $\{\emptyset, A, A^c, \Omega\}$ are $\sigma$-algebras.
  \end{example}

  \begin{example}
    Given a set $\Omega$, the smallest $\sigma$-algebra of $\Omega$ is
    $\{\emptyset, \Omega\}$ which is called the trivial $\sigma$-algebra.
  \end{example}
  
  \begin{proposition}
    Let $(\mathcal F_\alpha)_{\alpha \in I}$ be a family of $\sigma$-algebras,
    then $\cap_{\alpha \in I}{\mathcal F_\alpha}$ is a $\sigma$-algebra.
  \end{proposition}
  \begin{proof}
    Obvious.
  \end{proof}

  \begin{definition}[Minimal Sigma Algebra]
    Let $\Omega$ be a set, and let $H \subset 2^\Omega$ be a family of its
    subsets. Then we define the minimal sigma algebra that contains $H$,
    denoted $\sigma(H)$, as the intersection of all the $\sigma$-algebras
    that contains all the elements in $H$. Notice that the intersection is
    never empty because $2^\Omega$ is a $\sigma$-algebra that will always
    contain the elements of $H$.
  \end{definition}

  \begin{example}
    \tt{Borel's $\sigma$-algebra}
    One of the most important minimal $\sigma$-algebras, is Borel's 
    $\sigma$-algebra defined on $\R$. It is defined as such:
    \[
      \mathfrak B = \mathfrak B(\R) := \sigma(\set{(a,b)}{a < b}).
    \]
    That is, the smallest $\sigma$-algebra that contains all the open 
    intervals in $\R$. Similarly, we can define it on the space $\R^d$
    as follows:
    \[
      \mathfrak B_d = \mathfrak B(\R^d) := 
      \sigma\left(\set{\prod_{i=1}^{d}(a_i,b_i)}{a_i < b_i}\right).
    \]
    Note that in general, Borel's $\sigma$-algebra is defined to be
    the smallest $\sigma$-algebra that contains all the open sets in a
    general topological space. It can be showen that this definition is
    equivalent to the definitions we just gave for $\mathfrak B$ and
    $\mathfrak B_d$.
  \end{example}

  \begin{theorem}\label{thm:cath}
    \tt{Carath\'eodory}
    Let $\Omega$ be a set, let $\mathcal G$ be an algebra of sets of $\Omega$.
    If $\widehat{P} \colon \mathcal G \to [0,1]$ is a function that satisfies
    $f(\Omega) = 1$, and for each sequence of pairwise disjoint sets
    $\{A_n\}_{n=1}^{\infty}$ that
      \[
        \widehat{\mathbf P} \left(\bigcup_{n=1}^{\infty}{A_n}\right) = 
        \sum_{n=1}^{\infty}{\widehat{\mathbf P}(A_n)},
      \]
    then exists a single extension 
    $\mathbf P \colon \sigma(\mathcal G) \to [0,1]$ to 
    $\widehat{\mathbf P} \colon \mathcal G \to [0,1]$, such that the triplet
    $(\Omega, \sigma(\mathcal G), \mathbf P)$ is a probability space.
  \end{theorem}

  Now, if we consider again our previous problem, and let $\Omega = S^1$,
  in order to find a uniform probabiliy function on it we can define the
  set $\mathcal G$ to be the set of all finite unions of intervals on $S^1$.
  As it is closed under union of pairs, and complements, it is an algebra.
  Now define $\widehat{\mathbf P} \colon \mathcal G \to [0,1]$ as such:
  \[
    \widehat{\mathbf{P}}\left(\biguplus_{i=1}^{N}\left(a_{i},b_{i}\right)\right)
    = \sum_{i=1}^{N}\frac{b_{i}-a_{i}}{2\pi},
  \]
  We can see that $\widehat{\mathbf P}$ satisfies the conditions in 
  \autoref{thm:cath} and thus exists an extension $\mathbf P$ defined on
  the sigma algebra $\mathcal B = \sigma(\mathcal G)$ which is also called
  the Borel $\sigma$-algebra of $S^1$. We have that 
  $(\Omega, \mathcal B, \mathbf P)$ is a probability space and we call 
  $\mathbf P$ the uniform probability function on $S^1$.

  Now we can more formally consider the properties of probability functions.
  \begin{proposition}
    Let $(\Omega, \mathcal F, \mathbf P)$ be a probability space.
    \begin{enumerate}
      \item $\mathbf P(\emptyset) = 0$.
      \item If $\{A_n\}_{n=1}^{N} \subset \mathcal F$ are disjoint sets then
        $\cup_{n=1}^{n}{A_n} \in \mathcal F$ and
        \[
          \mathbf P\left(\bigcup_{n=1}^{n}{A_n}\right) = 
          \sum_{n=1}^{N}{\mathbf P(A_n)}.
        \]
      \item For every $A \in \mathcal F$ we have 
        $\mathbf P(A^c) = 1 - \mathbf P(A)$.
      \item If $A, B \in \mathcal F$ and $A \subset B$, then 
        $\mathbf(B \setminus A) = \mathbf P(B) - \mathbf P(A)$ and thus
        $\mathbf P(A) \le \mathbf P(B)$.
      \item If $A,B \in \mathcal F$, then
        \[
          \mathbf P(A \cup B) = 
          \mathbf P(A) + \mathbf P(B) - \mathbf P(A \cap B)
        \]
    \end{enumerate}
  \end{proposition}
  
  \begin{proposition}[Continuity of the Probability Function]
    Let $(\Omega, \mathcal F, \mathbf P)$ be a probability space.
    \begin{enumerate}
      \item If $(A_n)_{n=1}^{\infty} \subset \mathcal F$ is an increasing
        sequence of events, that is $A_1 \subset A_2 \subset A_3, \dots$,
        then
        \[
          \mathbf P\left(\bigcup_{n=1}^{\infty}{A_n}\right) = 
          \lim_{n \to \infty}{\mathbf A_n}.
        \]
      \item If $(A_n)_{n=1}^{\infty} \subset \mathcal F$ is a decreasing
        sequence of events, that is $A_1 \supset A_2 \supset A_3, \dots$,
        then
        \[
          \mathbf P\left(\bigcap_{n=1}^{\infty}{A_n}\right) = 
          \lim_{n \to \infty}{\mathbf A_n}.
        \]
    \end{enumerate}
  \end{proposition}

  In fact the last proposition is a not more than a case of the following
  proposition.

  \begin{proposition}
    Let $(A_n)_{n=1}^{\infty}$ be a sequence of events in a probability space
    $(\Omega, \mathcal F, \mathbf P)$. If the limit $\lim_{n \to \infty} A_n$
    exists, then $\lim_{n \to \infty} A_n \in \mathcal F$, and
    \[
      \mathbf P(\lim_{n \to \infty}{A_n}) = 
      \lim_{n \to \infty} \mathbf P(A_n)
    \]
  \end{proposition}
  
  Let us prove this theorem for the case $(A_n)_{n=1}^{\infty}$ is increasing.
  Define the following sequence:
  \begin{align*}
    B_1 &= A_1 \\
    B_n &= A_n \setminus A_{n-1}
  \end{align*}
  It is clear that:
  \begin{enumerate}
    \item The sets $(B_n)_{n=1}^{\infty}$ are disjoint.
    \item For every $N \in \N$ we have: 
      \[ \bigcup_{n=1}^{N} B_n = \bigcup_{n=1}^{N} A_n = A_N. \]
    \item $\cup_{n=1}^{\infty} B_n = \cup_{n=1}^{\infty} A_n$.
  \end{enumerate}
  We now have:
  \begin{align*}
    \mathbf P \left(\bigcup_{n=1}^{\infty} A_n\right) &=
    \mathbf P \left(\bigcup_{n=1}^{\infty} B_n\right) =
    \sum_{n=1}^{\infty} \mathbf(B_n) =
    \lim_{N \to \infty} \sum_{n=1}^{N} \mathbf P(B_n) =
    \lim_{N \to \infty} \mathbf P\left(\bigcup_{n=1}^{N} B_n\right) \\ &=
    \lim_{N \to \infty} \mathbf P(A_N).
  \end{align*}

  \newpage

  \section{Conditional Probability}
  \begin{definition}[Conditional Probability]
    Let $(\Omega, \mathcal F, \mathbf P)$ be a probability space, and let
    $A,B \in \mathcal F$, such that $\mathbf P(B) > 0$. We define the
    probability of $A$ given that $B$ already happened as:
    \[
      \mathbf P(A \mid B) := \frac{\mathbf P(A \cap B)}{\mathbf P(B)}
    \]
  \end{definition}

  The intuition behind this definition should be clear. We calculate the 
  probability of event $A$ ``inside'' event $B$.

  Notice that we can also use conditional probability to calculate the
  the probability of an intersection of two events.

  \begin{proposition}
    Let $(\Omega, \mathcal F, \mathbf P)$ be a probability space, let 
    $B \in \mathcal F$ be an event such that $\mathbf P(B) > 0$. Then,
    the map $A \mapsto \mathbf P(A \mid B)$ is a probability function.
  \end{proposition}
  The proof that the range of the function is $[0,1]$ and that 
  $\mathbf (\Omega \mid B) = 0$ is clear from expanding the definitions,
  so we will only prove sigma additivity.
  \begin{proof}
    Let $(A_n)_{n=1}^{\infty} \subset \mathcal F$ be disjoint sets, then
    $(A_n \cap B)_{n=1}^{\infty} \subset \mathcal F$ are also disjoint sets
    and we have:
      \begin{align*}
        \mathbf{P}\left( \bigcup_{n=1}^{\infty} A_n \mid B \right) 
        & = \frac{\mathbf{P}\left( \left( \bigcup_{n=1}^{\infty} A_n \right) \cap B \right)}{\mathbf{P}(B)} \\
        & = \frac{\mathbf{P}\left( \bigcup_{n=1}^{\infty} (A_n \cap B) \right)}{\mathbf{P}(B)} \\
        & = \sum_{n=1}^{\infty} \frac{\mathbf{P}(A_n \cap B)}{\mathbf{P}(B)} \\
        & = \sum_{n=1}^{\infty} \mathbf{P}(A_n \mid B)
      \end{align*}
  \end{proof}

  \begin{proposition}[Law of Total Probability]
    Let $(\Omega, \mathcal F, \mathbf P)$ be a probability space.
    Let $N \in \N \cup \{\infty\}$, and $(A_n)_{n=1}^{N}$ be disjoint events
    such that $\cup_{n=1}^{N} A_n = \Omega$. Then,
    \[
      \mathbf{P}(B)=\sum_{n=1}^{N}\mathbf{P}(A_{n})\mathbf{P}(B|A_{n}).
    \]
  \end{proposition}
  \begin{proof}
    \begin{align*}
      \mathbf{P}(B) &= 
      \mathbf{P}(B \cap \Omega) \\ &= 
      \mathbf{P}\left( B \cap \bigcup_{n=1}^{N} A_n \right) \\ &= 
      \mathbf{P}\left( \bigcup_{n=1}^{N} (A_n \cap B) \right) \\ &= 
      \sum_{n=1}^{N} \mathbf{P}(A_n \cap B) \\ &= 
      \sum_{n=1}^{N} \mathbf{P}(A_n) \mathbf{P}(B \mid A_n).
      \end{align*}
  \end{proof}

  \begin{example}[P\'olya's urn, simplified]
     Let there be $1$ white and $1$ black ball in an urn. 
     At each step, one ball is drawn uniformly at random from the urn, 
     and its color observed; 
     it is then returned in the urn, 
     and an additional ball of the same color is added to the urn.
     What is the probability that there are $k$ black balls in the urn after
     the $n$-th step?

     First denote:
     \begin{align*}
       A_{n,k} &= \{\text{there are $k$ black balls after the $n$-th step.}\} \\
       p_{n,k} &= \mathbf P(A_{n,k}).
     \end{align*}
     In order for there to be $k$ black balls after the $n$-th step, there must
     either have been $k-1$ or $k$ black balls in the $n-1$-th step. Thus,
     \begin{align*}
       \mathbf{P}(A_{n,k}) &= 
       \mathbf{P}(A_{n,k} \cap (A_{n-1,k-1} \cup A_{n-1,k})) \\ &= 
       \mathbf{P}(A_{n-1,k-1}) \mathbf{P}(A_{n,k} \mid A_{n-1,k-1}) + 
       \mathbf{P}(A_{n-1,k}) \mathbf{P}(A_{n,k} \mid A_{n-1,k}).
     \end{align*}
     This implies that
     \[ p_{n,k}=\frac{k-1}{n+1}p_{n-1,k-1}+\frac{n+1-k}{n+1}p_{n-1,k}. \]
     Coupled with the fact that $p_{0,1} = 1$ we can verify that the only
     solution under these conditions is $p_{n,k} = \frac{1}{n+1}$.
     In general, these problems are very hard to solve.
  \end{example}

  Another useful trick is Bayes' theorem.
  In its simplified version it states that,
  \[
    {\bf P}(A \mid B)={\frac{{\bf P}(B \mid A){\bf P}(A)}{{\bf P}(B)}},
  \]
  and can be solved without much thought. Here's the general theoerm.

  \begin{theorem}\tt{Bayes' Theorem}
    Let $(\Omega, \mathcal F, \mathbf P)$ be a probability space.
    Let $N \in \N \cup \{\infty\}$, and $(A_n)_{n=1}^{N}$ be disjoint events
    such that $\cup_{n=1}^{N} A_n = \Omega$. Then,
    \[
      \mathbf{P}(A_i \mid B) = 
      {\frac{\mathbf{P}(B \mid A_{i})\mathbf{P}(A_{i})}
      {\sum_{n=1}^{N}\mathbf{P}(A_{n})\mathbf{P}(B \mid A_{n})}}.
    \]
  \end{theorem}
  \begin{proof}
    Left as an exercise to the reader.
  \end{proof}

  \begin{example}
    Suppose we have a test for checking whether a person has the terrible 
    the terrible ``cooties''.
    It has a true positive rate of $0.98$, and a false positive rate of
    $0.01$. Assume that $0.1\%$ of the population has the cooties,
    what is the probability that a person who got a positive result
    has the cooties?

    Denote,
    \begin{align*}
      A &= \{\text{the person is healthy}\} \\
      B &= \{\text{the answer is positive}\}.
    \end{align*}
    From Bayes' theorem we have:
    \[
      \mathbf{P}(A \mid B) = 
      {\frac{\mathbf{P}(B \mid A)\mathbf{P}(A)}{\mathbf{P}(B)}} = 
      {\frac{0.01\cdot0.999}{\mathrm{P}(B)}}.
    \]
    From the law of total probability we have
    \begin{align*}
      \mathbf{P}(B) &= 
      \mathbf{P}(A)\mathbf{P}(B \mid A) + 
      \mathbf{P}(A^{c})\mathbf{P}(B \mid A^{c}) \\ &= 
      0.01\cdot0.999+0.98\cdot0.001=0.01097.
    \end{align*}
    And thus,
    \[ \mathbf{P}(A \mid B)={\frac{0.01\cdot0.999}{0.01097}} \approx 0.91 \]
  \end{example}

  % There's another example here that might be useful

  \newpage

  \section{Independance and Repeating Experiments}
  Intuitively, when we say that the event $A$ is independent from $B$,
  we mean something like
  \[
    \mathbf P(A \mid B) = \mathbf P(A).
  \]
  Thus we can use the definition of conditional probability to formally define
  Independence.
  \begin{definition}[Independence of Two Events]
    Let $(\Omega, \mathcal F, \mathbf P)$ be a probability space, let 
    $A,B \in \mathcal F$ be two events. We say that $A$ and $B$ are independent,
    if
    \[
      \mathbf P(A \cap B) = \mathbf P(A) \mathbf P(B)
    \]
  \end{definition}
  Notice that the interpretation that $A$ is independent of $B$ is only viable
  if we know that $\mathbf P(B) > 0$.

  % More examples of Independence.

  \begin{proposition}
    Let $(\Omega, \mathcal F, \mathbf P)$ be a probability space,
    let $A \in \mathcal F$. The following conditions are equivalent:
    \begin{enumerate}
      \item For each $B \in \mathcal F$ the events $A$ and $B$ are independent.
      \item $A$ is independent of itself.
      \item $\mathbf P(A) \in \{0, 1\}$.
    \end{enumerate}
  \end{proposition}
  \begin{proof}
    Clear from the definitions.
  \end{proof}
  
  \begin{definition}[Independence]
    Let $(\Omega, \mathcal F, \mathbf P)$ be a probability space,
    let $(A_n)_{n=1}^{N}$ be a finite sequence of events.
    We say that $(A_n)_{n=1}^{N}$ are independent if for each 
    $\emptyset \neq K \subset \{1,2,\dots,N\}$ we have
    \[
      \mathbf P\left(\bigcap_{n \in K} A_n\right) = 
      \prod_{n \in K} \mathbf P(A_n).
    \]
  \end{definition}

  \begin{definition}[Pairwise Independence]
    Let $(\Omega, \mathcal F, \mathbf P)$ be a probability space,
    let $(A_n)_{n=1}^{N}$ be a finite sequence of events.
    We say that $(A_n)_{n=1}^{N}$ are independent if for each 
    $1 \le i < j \le N$ we have
    \[
      \mathbf P(A_i \cap A_j) = 
      \mathbf P(A_i) \mathbf P(A_j).
    \]
  \end{definition}

  \begin{definition}[Independence of Infinite Events]
    Let $(\Omega, \mathcal F, \mathbf P)$ be a probability space,
    let $(A_n)_{n=1}^{\infty}$ be an infinite sequence of events.
    We say that $(A_n)_{n=1}^{\infty}$ are (pairwise) independent if each
    finite subset of them is (pairwise) independent.
  \end{definition}

  Note that we only require independence for finite subsets and not for
  infinite subsets.

  \begin{proposition}\label{prop:indp}
    Let $(\Omega, \mathcal F, \mathbf P)$ be a probability space,
    let $(A_n)_{n=1}^{\infty}$ be an infinite sequence of  (pairwise) 
    independent events. Then define a new sequence 
    $(\widetilde{A}_n)_{n=1}^{\infty}$ such that $\widetilde{A}_n = A_n$ or
    $\widetilde{A}_n = A_n^c$ for each $n \in \N$. Then each choice of such
    $(\widetilde{A}_n)_{n=1}^{\infty}$ is (pairwise) independent.
  \end{proposition}
  \begin{proof}
    Using induction on the number of index such that we chose
    $\widetilde{A}_n = A_n^c$. 
    To be completed.
  \end{proof}

  Now, we have the tools to define probability spaces for repeating experiments.
  We assume that the experiment is repeated in exactly the same way, and that
  the results of each experiment are independent.

  Let $(\Omega, \mathcal F, \mathbf P)$ be a probability space for a certain
  experiment. If we want to define a probability space for repeating the
  the experiment a finite number of times, which we will denote $N$, it makes
  sense to define it as such:
  \begin{align*}
    &\Omega_N = \Omega^N. \\
    &\mathcal F_N = \sigma\left(\set{A_1 \times A_2 \times \cdots \times A_n}
    {A_1,\dots,A_n \in \mathcal F}\right). \\
    &\mathbf P_N\left(A_1 \times A_2 \times \cdots A_N\right) = 
    \prod_{i=1}^{N} \mathbf P(A_i).
  \end{align*}
  The fact that $\mathbf P_N$ is a probability measure follows from 
  \autoref{thm:cath}. This measure is called the product measure, and 
  $\mathcal F_N$ is called the product $\sigma$-algebra.

  Similarly, when $N=\infty$, we will define the space to be:
  \begin{align*}
    &\Omega_N = \Omega^{\N}. \\
    &\mathcal F_N = \sigma\left(\set{\prod_{i=1}^{\infty}{A_i}}
    {A_i \in \mathcal F, \, \forall i \geq 1 \text{ and only for finitely many
    $i$'s } A_i \neq \Omega}\right). \\
    &\mathbf P_N\left(\prod_{i=1}^{N}{A_i}\right) = 
    \prod_{i=1}^{N} \mathbf P(A_i).
  \end{align*}
  Notice that we defined the probability function only on finite products of
  events. The extenstion to the rest of the sets will be done by 
  \autoref{thm:cath}.

  \begin{example}[Bernoulli Trial]
    A Bernoulli trial, is a random experiment with only two possible outcomes,
    ``success'' and ``failure'', in which the probability of success is the 
    same every time the experiment is conducted. The probability space that
    models these kind of experiments is defined as such:
    \begin{align*}
      \Omega &= \{0, 1\}. \\
      \mathcal F &= \{\emptyset, \{0\}, \{1\}, \Omega\}. \\
      \mathbf P(\omega) &=
      \begin{cases}
        p, &\omega = 1 \\
        1-p, &\omega= 0
      \end{cases}
    \end{align*}
    Now for $N \in \N \cup \{\infty\}$ we have
    \[ \Omega_N = \{0, 1\}^N \]
    which models repeating independent experiment with two results.
    These kind of experiments are also called Bernoulli trials.

    Now set $N \in \N$. We want to calculate the probability that the
    experiment ends in $k$ successes. We set:
    \begin{align*}
      A_k &= \{\text{$k$ successes}\}. \\
      H_i &= \{\omega_i = 1\}, \quad 1 \le i \le N.
    \end{align*}
    We now notice that if $\omega = (\omega_1,\dots,\omega_N) \in A_k$ then
    \[
      \{\omega\} = \bigcap_{i=1}^{N} \widehat{H}_i,
    \]
    where
    \[
      \widetilde{H}_{i} = 
      \begin{cases}
        H_{i}, &\omega_{i} = 1 \\ 
        H_{i}^{c}, &\omega_{i} = 0
      \end{cases}.
    \]
    From \autoref{prop:indp} and since the events are independent:
    \[
      \mathbf P_N\left(\{w\}\right) =
      \mathbf P_N\left(\bigcap_{i=1}^{N} \widetilde{H}_i \right) = 
      \prod_{i=1}^{N} \mathbf P_N(\widetilde{H}_i) =
      p^k (1-p)^{N-k}
    \]
    Finally, we get
    \[
      P_N(A_k) = 
      \abs{A_k} p^k (1-p)^{N-k} = 
      \binom{N}{k} p^k (1-p)^{N-k}
    \]
    Also, because we know that $(A_k)_{k=1}^{N}$ are all disjoint and that
    $\cup_{k=1}^{N} A_k = \Omega$ we get that:
    \[
      \sum_{k=0}^{N}\mathbf{P}_{N}\left(A_{k}\right) = 
      \sum_{k=0}^{N}{\binom{N}{k}}p^{k}\left(1-p\right)^{N-k} = 
      \left(p+\left(1-p\right)\right)^{N} = 1,
    \]
    just as expected.
  \end{example}

  \begin{example}[Random Walks]
    Let there be a cute cat on the $\Z$ number line. 
    We know that each minute, the cat could move one step to the right with
    a probability of $p$, or one step to the left with probability $1-p$.
    We may wonder what are the chances the cat would be on the number $4$
    after $8$ minutes.

    It's not hard to see that this experiment is just like the previous
    experiment, and indeed if we denote $A_k$ the number of step the cat
    made to the right after in the product probability space 
    $(\Omega_8, \mathcal F_8, \mathbf P_8)$, we would get that:
    \[
      \mathbf P_8(A_k) = \binom{8}{k} p^k (1-p)^{8-k}.
    \]
    The position of the cat after $k$ step to the right would be 
    $k - (8 - k) = 2k - 8$. 
    Since we wonder about the probability of it being on the number $4$,
    we should calculate the probability of $A_6$, and we will get that:
    \[
      \mathbf{P}_{8}(A_{6}) = {\binom{8}{6}} p^{6} (1-p)^{8-6}.
    \]
    Notice that the result makes sense because as $P$ increases we get higher
    results.
  \end{example}
  \begin{example}[Infinite coin flips]
    We now consider the probability space 
    $(\Omega_{\infty}, \mathcal F_{\infty}, \mathbf P_{\infty})$
    corresponding to the product space of infinite Bernoulli experiments.
    We want to calculate the probability that the first success was in 
    the $n$-th experiment. Denote:
    \begin{align*}
      H_i &= \{\text{the $i$-th experiment resulted in success}\} \\
      R_n &= \{\text{first success was in the $n$-th experiment}\} = 
      \left(\bigcap_{i=1}^{n-1} H_i^c\right) \cap H_n.
    \end{align*}
    Since all the Bernoulli experiments are independent, from 
    \autoref{prop:indp} we get
    \[
      \mathbf{P}_{\infty}(R_{n}) = 
      \mathbf{P}_{\infty} \left(\left(\bigcap_{i=1}^{n-1} H_i^c\right) \cap H_n\right) = 
      \left(\prod_{i=1}^{n-1} \mathbf{P}_{\infty} \left(H_{i}^{c}\right)\right) \cdot \mathbf{P}_{\infty} \left(H_{n}\right) =
      (1-p)^{n-1}p.
    \]
    We may notice that the events $(A_n)_{n=1}^{\infty}$ are all independent,
    and also that
    \[
      \bigcup_{n=1}^{\infty} R_n = \Omega_\infty \setminus \{(0,0,0,\dots)\}.
    \]
    And as long as $p > 1$, we may assume that 
    $\mathbf P_\infty(0,0,0,\dots) = 0$.
    Using that assumption, we have that
    \begin{align*}
      \mathbf P_{\infty}(\{0,0,0,\dots\}) &= 
      1 - \mathbf P_\infty(\Omega_\infty \setminus \{0,0,0,\dots\}) =
      1 - \mathbf P_\infty(\bigcup_{n=1}^{\infty} R_n) \\ &=
      1 - \sum_{n=1}^{\infty} \mathbf P_\infty(R_n) =
      1 - p \sum_{n=1}^{\infty} (1-p)^{n-1} \\ &=
      \begin{cases}
        0, &p \in (0,1) \\
        1, &p = 0 \\
        0, &p = 1
      \end{cases}.
    \end{align*}
  \end{example}

  \newpage

  \section{Random Variables}
  % Add introduction
  (add introduction)
  \begin{definition}[Random Variable]
    Let $(\Omega, \mathcal F, \mathbf P)$ be a probability space.
    A function $X \colon \Omega \to \R$ is called a random variable if for
    any open interval $(a,b) \subset \R$ we have
    \[
      X^{-1}\left((a,b)\right) = 
      \set{\omega \in \Omega}{X(\omega) \in (a,b)} \in \mathcal F.
    \]
  \end{definition}
  \begin{remark}
    From now on we denote
    \[
      \{X \in A\} = \set{\omega \in \Omega}{X(\omega) \in A}
    \]
  \end{remark}
  
  Here are a couple of things we shuold notice:
  \begin{enumerate}
    \item If we have that $\Omega$ is countable then as we know 
    $\mathcal F = 2^\Omega$ and thus every function $X \colon \Omega \to \R$
    is a random variable.
    \item If we denote 
    \[
      \mathcal G_X := \set{D \subset \R}{\{X \in D\} \in \mathcal F},
    \]
    we can notice that $\R \in \mathcal G_X$, and that $\mathcal G_X$ is
    closed under countable unions, and complements. 
    Thus, it is a $\sigma$-algebra of $\R$.
    We also have that it contains all the open intervals in $\R$ so we
    get that $\mathfrak B := \mathfrak B(\R) \subset \mathcal G_X$.
  \end{enumerate}
  
  \begin{definition}[Distribution of a Random Variable]
    Let $(\Omega, \mathcal F, \mathbf P)$ be a probability space, and 
    $X \colon \Omega \to \R$ a random variable.
    The distribution of $X$, denoted $P_X$ is the function 
    $\mathbf P_X \colon \mathfrak B \to [0,1]$ defined as such:
    \[
      \mathbf P_X(A) = \mathbf P(X \in A).
    \]
  \end{definition}
  \begin{remark}
    The space $(\Omega, \mathfrak B, \mathbf P_X)$ is a probability space.
  \end{remark}
  \begin{remark}
    Since a random variable $X$ gives us data about experiments, for events
    $N \in \mathcal F$ such that $\mathbf P(N) = 0$ we don't care about the
    value of $X(N)$. From now on we won't define random variables for events
    with probability $0$.
  \end{remark}
  
  \begin{example}
    There are $20$ balls in a vase, numbered from $1-20$.
    Three balls are taken out of a vase with a uniform probability.
    What is the probability that one of the balls is numbered $17$ or above?

    First we define our sample space
    \[
      \Omega = \set{(i,j,k)}{1 \le i \le j \le k \le 20}.
    \]
    Since the balls are taken out uniformly we have 
    \[ \mathbf P\left((i,j,k)\right) = {\binom{20}{3}}^{-1}. \]
    We now define the random variable:
    \begin{align*}
      &X \colon \Omega \to \R \\
      &X\left((i,j,k)\right) = k
    \end{align*}
    and we notice that we want to calculate 
    $\mathbf P\left(X \in \{17,18,19,20\}\right)$.
    Since $\mathbf P_X$ is a probability function we can see that:
    \begin{align*}
      \mathbf P\left(X \in \{17,18,19,20\}\right) &= 
      \mathbf P_X\left(\{17,18,19,20\}\right) \\ &=
      \mathbf P_X\left(\{17\}\right) + 
      \mathbf P_X\left(\{18\}\right) +
      \mathbf P_X\left(\{19\}\right) +
      \mathbf P_X\left(\{20\}\right) +
    \end{align*}
    We notice that:
    \[
      \mathbf P_X\left(\{k\}\right) = \frac{\binom{k-1}{2}}{\binom{20}{3}}
    \]
    So finally we have:
    \[
      \mathbf P\left(X \in \{17,18,19,20\}\right) = 
      {\binom{20}{3}}^{-1} 
      \left[
        \binom{16}{2} + \binom{17}{2} + \binom{18}{2} + \binom{19}{2}
      \right]
      \approx 0.508
    \]
  \end{example}

  \begin{example}[Coupon Collector]
    There are $N$ types of coupons in a certain game, and we want to collect
    them all. 
    Thus, each day we buy a new coupon, such that the probability of getting
    each one is the same.
    The sample space is $\Omega = \{1,2,\dots,N\}^{\N}$.
    We define a random variable $T \colon \Omega \to \R$ as such:
    \[
      T(\omega) = 
      \inf\left\{\set{k \geq 1}{\abs{\{\omega_1,\dots,\omega_k\} = N}}\right\}.
    \]
    Notice that $T$ is undefined for $\omega \in \Omega$ that doesn't include
    all the coupons, so we need to show that the probability of such events
    is zero. It would be easier to do it later, so we will assume that for
    now. For $j \geq N$ and $1 \le j \le N$ we define
    \[
      A_t(j) = \{\text{we didn't find a coupon of type $j$ up to day $t$}\}.
    \]
    Notice that:
    \[
      \{T > t\} = \bigcup_{j=1}^{N} A_t(j).
    \]
    Thus,
    \[
      \mathbf P_T\left((t,\infty)\right) =
      \mathbf P_T\left(\{t + 1, t + 2, \dots\}\right) =
      \mathbf P\left(\bigcup_{j=1}^{N} A_t(j) \right)
    \]
    The events $A_t(j)$ are not disjoint but using the inclusion--exclusion
    principle we get
    \[
      \mathbf P\left(\bigcup_{j=1}^{N} A_t(j) \right) =
      \sum_{t=1}^{N}(-1)^{i+1} 
      \sum_{\substack{J\subset\{1,2,..,N\} \\ \abs{J} = i}}
      \mathbf{P}\left(\bigcap_{j\in J}A_{t}(j)\right).
    \]
    We can notice that
    \[
      \mathbf{P}\left(\bigcap_{j\in J}A_{t}(j)\right) = 
      \left(\frac{N - \abs{J}}{N}\right)^t.
    \]
    Summing up the results so far gives
    \[
      \mathbf P_T\left(\{t + 1, t + 2, \dots\}\right) =
      \sum_{\substack{J\subset\{1,2,..,N\} \\ \abs{J} = i}}
      \left(\frac{N - \abs{J}}{N}\right)^t =
      \sum_{i=1}^{N} (-1)^{i+1} \binom{N}{i} \left(\frac{N-i}{N}\right)^{t}.
    \]
    Because the image of $T$ is $\N$ we can write
    \begin{align*}
      \mathbf P_T\left(\{t\}\right) &=
      \mathbf P_T\left(\{t, t + 1, \dots\}\right) -
      \mathbf P_T\left(\{t + 1, t + 2, \dots\}\right) \\ &=
      \sum_{i=1}^{N}(-1)^{i+1}\binom{N}{i}\left(\frac{N-i}{N}\right)^{t-1} -
      \sum_{i=1}^{N}(-1)^{i+1}\binom{N}{i}\left(\frac{N-i}{N}\right)^{t} \\ &=
      \sum_{i=1}^{N}(-1)^{i+1}\binom{N}{i}\left(\frac{N-i}{N}\right)^{t}
      \left(1 - \frac{N-i}{N}\right).
    \end{align*}
    Now all that's left to show is that the probability of events where we
    didn't get all the coupons is zero. For $1 \le j \le N$ we define the
    event $A(j) = \{\text{we didn't find the coupon of type $j$}\}$ and notice
    that:
    \[
      A(j) = \bigcap_{t=1}^{\infty} A_t(j).
    \]
    Since $A_t(j)$ is a decreasing sequence of events (in $t$), it is clear
    that $A(j) \in \mathcal F$. Since probability functions are continuous
    we have that
    \[
      \mathbf{P}(A(j)) =
      \mathbf{P}\left(\bigcap_{t=1}^{\infty}A_{t}(j)\right) =
      \lim_{t\to\infty}\mathbf{P}\left(A_{t}(j)\right) =
      \lim_{t\to\infty}\left({\frac{N-1}{N}}\right)^{t}=0.
    \]
    And so get
    \[
      \mathbf P(\text{we didn't find one of the coupons}) =
      \mathbf{P}\left(\bigcup_{j=1}^{N} A(j)\right) \leq
      \sum_{j=1}^{N} \mathbf{P}(A(j)) =
      \sum_{j=1}^{N} 0 =
      0.
    \]
  \end{example}
  \begin{definition}[Support]
    The support of a random variable $X \colon \Omega \to \R$ is the set of all $a \in \R$
    such that for all $\varepsilon > 0$ we have 
    $\mathbf P_X\left((a - \varepsilon, a + \varepsilon)\right) > 0$.
    For a general function $f \colon A \to \R$ such that $X$ is a topological
    space we have
    \[
      \operatorname {supp} (f) := 
      \operatorname {cl}_{A} 
      \left(\{x\in A\,:\,f(x)\neq 0\}\right) =
      {\overline {f^{-1}\left(\{0\}^{\mathrm {c} }\right)}}.
    \]
  \end{definition}
  \begin{definition}
  [Cumulative Distribution Function]
    Let $(\Omega, \mathcal F, \mathbf P)$ be a probability space,
    and let $X \colon \Omega \to \R$ be a random variable.
    The cumulative distibution function (CDF) of $X$, denoted $F_X$ is
    a function $F_X \colon \R \to [0,1]$ defined as such
    \[
      F_{X}(a) = \mathbf{P}_{X}((-\infty,a]) \equiv \mathbf{P}(X \leq a).
    \]
    \end{definition}
  \begin{proposition}
    Let $(\Omega, \mathcal F, \mathbf P)$ be a probability space,
    and let $X \colon \Omega \to \R$ be a random variable.
    The function $F_X$ satisfies the following properties:
    \begin{enumerate}
      \item $F_X$ is a monotonically increasing function.
      \item $\lim_{a \to \infty} F_X(a) = 1$.
      \item $\lim_{a \to -\infty} F_X(a) = 0$.
      \item $F_x$ is continuous from the right.
    \end{enumerate}
  \end{proposition}
  The proofs of $1-3$ are derived from basic properties of probability
  functions, and that they are continuous, so we will only prove the last
  statement.
  \begin{proof}
    Let $a \in \R$.
    Since $F_X$ is monotonically increasing, it suffices to show the continuity
    for a single sequence, for example $a_n = a + \frac{1}{n}$. We see
    that
    \begin{align*}
      \lim_{n\to\infty} F_{X} {\left(a+\frac{1}{n}\right)} &=
      \lim_{n\to\infty} \mathbf P_{X}{\left((-\infty,a+1/n]\right)} =
      \mathbf P_{X}{\left(\bigcap_{n=1}^{\infty}(-\infty,a+1/n)\right)} \\ &=
      \mathbf P_{X}{\left((-\infty,a)\right)} =
      F_{X}(a),
    \end{align*}
  \end{proof}
  The following theorem will show that $F_X$ contains by itself all the
  information from $P_X$, but we will not prove it in this course.
  \begin{theorem}\label{thm:FcharacterizesP}
    Every CDF corresponds to a unique distribution. In other words, if
    $(\Omega, \mathcal F, \mathbf P)$ and $(\Omega', \mathcal F', \mathbf P')$
    are two probability spaces, and $X \colon \Omega \to \R$, 
    $Y \colon \Omega' \to \R$ are two random variable, then
    \[
      F_X = F_Y \iff \mathbf P_X = \mathbf P_Y
    \]
  \end{theorem}
  \begin{theorem}
    Let $F \colon \R \to [0,1]$ be a function that satisfies all $4$ basic
    properties of the CDF. Thus, exists a probability space 
    $(\Omega, \mathcal F, \mathbf P)$ and a random variable 
    $X \colon \Omega \to \R$ such that$F_X = F$.
  \end{theorem}
  We won't prove this theorem either, but using these two last theorems
  we can conclude that exists a bijection between all random variables'
  distributions and functions that satisfy the $4$ properties from above.

  \begin{definition}
    Let $(\Omega ,\mathcal F, \mathbf P)$ be a probability space,
    and let $X \colon \Omega \to \R$ be a random variable.
    We say that $X$ is a discrete random variable if $\supp(X)$ is a 
    countable set.
  \end{definition}
  \begin{remark}
    Notice that if $X \colon \Omega \to \R$ is a random variable such
    that $\Omega$ is countable, then it is necessarily a discrete random
    variable.
  \end{remark}
  \begin{remark}
    Let $(\Omega ,\mathcal F, \mathbf P)$ be a probability space,
    and let $X \colon \Omega \to \R$ be a discrete random variable.
    Denote $\supp(X) = \{a_i\}_{i=1}^{\infty}$ and $p_i := \mathbf P(\{a_i\})$.
    By definition of the support we have that $\sum_{i=1}^{\infty} p_i = 1$,
    and thus, since $\mathbf P_X$ is a probability function we have that
    for any interval $(a,b) \subset \R$ we have
    \[
      \mathbf P_X \left((a,b)\right) = \sum_{i \colon a_i \in (a,b)} p_i.
    \]
    And that the CDF of $X$ is
    \[
      F_X(a)
      \mathbf P_X \left((-\infty,a)\right) = \sum_{i \colon a_i \le a} p_i.
    \]
    This means that the CDF of a discrete random variable $X$ is an a step
    function. In fact, a random variable $X$ is discrete if and only if
    $F_X$ is a step function.
  \end{remark}

  \begin{definition}[Binomial Distribution]
    Let $(\Omega ,\mathcal F, \mathbf P)$ be a probability space,
    and let $X \colon \Omega \to \R$ be a random variable.
    We say that $X$ is a binomial random variable with parameters
    $n \in \N$ and $p \in [0,1]$ if it's range is $\{0,1,2,\dots,n\}$ and
    it's distribution satisfies
    \[
      \mathbf P_X(k) = \binom{n}{k} p^k (1-p)^{n-k}, \quad 
      \forall k \in \{0,1,2,\dots,n\}.
    \]
    Alternatively, $X$ is a binomial random variable with parameters
    $p$ and $n$ if
    \[
      F_X(a) = \sum_{\substack{k \le a \\ k \in \{0,1,2,\dots,n\}}}
      \binom{n}{k} p^k (1-p)^{n-k}, \quad \forall a \in \R.
    \]
    In this case we denote $X \sim \Bin(n,p)$.
  \end{definition}
  When we talked about repeating Bernoulli experiments we saw that the number
  of ``success'' results in $n$ experiments follows $\Bin(n,p)$ where
  $p$ is the probability of success in a single experiment.
  
  \begin{example}
  It is said that Hercules had a $90\%$ chance to complete each
  one of his $12$ deadly labours. We all know that he eventually completed
  all of them, and gained immortality. But how easier would it be, if he
  was allowed to fail one or two?
  \begin{align*}
    \mathbf P_X(\{1,2\}) - \mathbf P_X(\{0\}) &=
    \mathbf P_X(\{1\}) + \mathbf P_X(\{2\}) - \mathbf P_X(\{0\}) \\ &=
    \sum_{k \in \{1,2\}}
    \binom{12}{k} (0.1)^k (k - (0.1))^{12-k} +
    \binom{12}{0} (0.1)^0 (1 - (0.1))^{12-0} \\ &\approx
    0.325
  \end{align*}
  \end{example}
  \begin{example}
    Suppose we flip a fair coin $2000$ times. You may be able to convince
    yuor friend it's safe to bet on the chances it falls on heads exactly
    $1000$ times. After all, it's a fair coin, so flipping it a large number
    of times means it's safe to assume it fell on head $50\%$ of the time
    right? Let's find out. The amount of times we get head follows
    $\Bin(2000,0.5)$ so we have
    \[
      \mathbf{P}_{X}(1000) =
      \binom{2000}{1000} \left(\frac{1}{2}\right)^{1000}
      \left(\frac{1}{2}\right)^{1000} =
      \frac{(2000)!}{(1000!)^{2}2^{2000}}.
    \]
    Using Stirling's approximation
    \[
      \lim_{n\rightarrow\infty}
      {\frac{n!}{\sqrt{2\pi}n^{n+1/2}e^{-n}}}=1,
    \]
    we get that
    \[
      \mathbf{P}_{X}(1000) \approx
      \frac{\sqrt{2\pi}(2000)^{2000+1/2}e^{-2000}}
          {({\sqrt{2\pi}}1000^{1000+1/2}e^{-1000})^{2}2^{2000}} =
      {\frac{1}{\sqrt{\pi 1000}}}.
    \]
    Turns out it wasn't such a good idea\dots
  \end{example}

  \begin{definition}[Geometric Distribution]
    Let $(\Omega ,\mathcal F, \mathbf P)$ be a probability space,
    and let $X \colon \Omega \to \R$ be a random variable.
    We say that $X$ is a geometric random variable with parameter
    $p \in [0,1]$ if it's range is $\N$ and it's distribution satisfies
    \[
      \mathbf P_X(k) = (1-p)^{k-1} p, \quad 
      \forall k \in \N.
    \]
    Alternatively, $X$ is a geometric random variable with parameter
    $p$ if
    \[
      F_X(a) = \sum_{\substack{k \le a \\ k \in \N}}
      (1-p)^{k-1} p, \quad \forall a \in \R.
    \]
    In this case we denote $X \sim \Geo(p)$.
  \end{definition}
  
  \begin{example}
    Suppose we had a Bernoulli experiment repeated indefininely, or until
    we get a success. Let $p$ denote the probability of success.
    The random variable the calculates the first repetition in which the
    experiment succeeded follows $\Geo(p)$.
  \end{example}

  \begin{definition}
    Let $(\Omega ,\mathcal F, \mathbf P)$ be a probability space,
    and let $X \colon \Omega \to \R$ be a random variable.
    We say that $X$ is a Poisson random variable with parameter
    $p > 0$ if it's range is $\N$ and it's distribution satisfies
    \[
      \mathbf P_X(k) = e^{-\lambda} \frac{\lambda^k}{k!}, \quad 
      \forall k \in \N.
    \]
    Alternatively, $X$ is a Poisson random variable with parameter
    $p$ if
    \[
      F_X(a) = \sum_{\substack{k \le a \\ k \in \N}}
      e^{-\lambda} \frac{\lambda^k}{k!}, \quad \forall a \in \R.
    \]
    In this case we denote $X \sim \Poi(p)$.
  \end{definition}
  
  This is a rather odd distribution. It is mostly used to model rare events.
  Suppose that an event happens at a rate of $\lambda$.
  We can try to model this by thinking of repeating a lot of trials,
  say $n$ of them, and in each there is a a probability $\lambda / n$ of 
  succeeding. This bigger $n$ we choose, the more accurate the model will get.
  As we take the limit $n \to \infty$, we obtain the Poisson distribution.
  
  We can also notice that the Poisson distribution is really similar to
  the binomial distibution, in fact, it is exactly an approximation of it.

  \begin{theorem}[Poisson approximation to binomial]
    Suppose that $X \sim \Bin(n,k)$ and we have
    $np = \lambda$. Then
    \[
      \mathbf P(X = k) = 
      \binom{n}{k} p^{k} (1-p)^{n-k} \xrightarrow{n\to\infty}
      \frac{\lambda^{k}}{k!} e^{-\lambda}.
    \]
  \end{theorem}
  \begin{proof}
    \begin{align*}
      \mathbf {P}(X = k) &= 
      {\binom{n}{k}}p^{k}(1 - p)^{n - k} \\ &= 
      {\frac{n(n - 1) \cdots (n - k + 1)}{k!}} 
      \left(\frac{\lambda}{n}\right)^k
      \left(1 - {\frac{\lambda}{n}}\right)^{n-k} \\ &= 
      \frac{\lambda^{k}}{k!} \left(1-{\frac{\lambda}{n}}\right)^{n} \cdot
      \underbrace{
      \left( {\frac{n}{n}} \cdot 
      {\frac{n - 1}{n}} \cdots {\frac{n - k + 1}{n}} \right) \cdot 
      \left(1 - {\frac{\lambda}{n}}\right)^{-k}}_{(*)}.
    \end{align*}
    As we take the limit $n \to \infty$ we have $(*) \to 1$ and thus
    \[
      \lim_{n\to\infty}\mathbf{P}(X=k)=e^{-\lambda}{\frac{\lambda^{k}}{k!}}.
    \]
  \end{proof}

  Before moving on to continuous random variables, we will prove a theorem
  from a very unexpected field.
  \begin{theorem}[Divergence of the sum of the reciprocals of the primes]
    \label{thm:drp}
    We want to show that
    \[
      \sum _{p{\text{ prime}}}{\frac {1}{p}} =
      {\frac {1}{2}}+
      {\frac {1}{3}}+
      {\frac {1}{5}}+
      {\frac {1}{7}}+
      \cdots = \infty.
    \]
  \end{theorem}
  Before proving this theorem, we need cover some more things.
  \begin{definition}[Riemann zeta function]
    For any real number $s > 1$ the Riemann zeta function is defined
    as such
    \[
      \zeta(s) = \sum_{n=1}^{\infty} n^{-s}.
    \]
  \end{definition}
  \begin{lemma}[Euler's product formula]\label{lem:epf}
    \[
      \zeta (s) =
      \sum _{n=1}^{\infty }{\frac {1}{n^{s}}} =
      \prod _{p{\text{ prime}}}{\frac {1}{1-p^{-s}}}
    \]
    where $\zeta(s)$ is visibly the Riemann zeta function, and $s$
    is a real number greater than $1$.
  \end{lemma}
  \begin{proof}
    Let $s > 1$ be a real number. Define a discrete random variable $X$,
    with range (support) $\{1,2,\dots\}$, with the following distribution
    \[
      \mathbf P_X(k) = \frac{k^{-s}}{\zeta(s)},
    \]
  where $\zeta(s)$ is the Riemann zeta function.
  This assures us that $\mathbf P_X(\N) = 1$. 
  For any natural number $m$ set
  \[
    A_m = 
    \set{k \in \N}{\text{$k$ is divisible by $m$}} =
    \set{nm}{n \in \N}.
  \]
  Since $\mathbf P_X$ is a probability function we get that for any $m \in N$
  \begin{align*}
    \mathbf{P}_{X}\left(A_{m}\right) 
    &= \sum_{k \in A_{m}} \mathbf{P}_{X}\left(k\right)
    = \sum_{n=1}^{\infty} \mathbf{P}_{X}\left(n m\right)
    = {\frac{1}{\zeta(s)}} \sum_{n=1}^{\infty} \left(n m\right)^{-s} \\
    &= {\frac{m^{-s}}{\zeta(s)}} \sum_{n=1}^{\infty} n^{-s}
    = {\frac{m^{-s}}{\zeta(s)}} \zeta(s)
    = m^{-s}.
  \end{align*}
  We can notice that for any two distinct primes $p \neq q$ that the events
  $A_q$ and $A_p$ are independent. That is because $A_p \cap A_q = A_{pq}$,
  and then
  \[
    \mathbf P_X(A_p \cap A_q) =
    \mathbf P_X(A_{pq}) =
    (pq)^{-s} =
    p^{-s} q^{-s} =
    \mathbf P_X(A_p) \mathbf P_X(A_q).
  \]
  Similarly, we can show that for any finite number of primes 
  $\{p_i\}_{i=1}^{N}$ that the events $\{A_{p_i}\}_{i=1}^{N}$ are independent.

  Finally, since every integer greater than $1$ is divisible by at least
  one prime number
  \[
    \bigcap_{p\text{ prime}} A_p^c = \{1\},
  \]
  we get that
  \[
    {\frac{1}{\zeta(s)}} = 
    \mathbf{P}_{X}\left(\left\{1\right\}\right) = 
    \mathbf{P}_{X}\left(\bigcap_{p \ \mathrm{prime}} A_{p}^{c}\right) = 
    \prod_{p \ \mathrm{prime}} \mathbf{P}_{X}\left(A_{p}^{c}\right) = 
    \prod_{p \ \mathrm{prime}} \left(1 - \frac{1}{p^{s}}\right),
  \]
  which completes the proof.
  \end{proof}
  Now that we have Euler's product formula we can prove \autoref{thm:drp}.
  \begin{proof}
    Because we already know from analysis that 
    $\sum_{n \in \N} \frac 1n = \infty$ we get that
    \begin{align*}
      \lim_{s \to 1^+}
      \exp\left(\sum_{p \ \mathrm{prime}}
      \ln \left(1 - \frac{1}{p^{s}}\right)\right) &=
      \lim_{s \to 1^+}
      \exp \left(\ln\left(\prod_{p \ \mathrm{prime}}
      \left(1 - \frac{1}{p^{s}}\right)\right)\right) \\ &= 
      \lim_{s \to 1^+} 
      \prod_{p \ \mathrm{prime}} \left(1 - \frac{1}{p^{s}}\right) \\ &= 
      \infty.
    \end{align*}
    Now from the exponent function properties we get that
    \[
      \lim_{s \to 1^+} 
      \sum_{p \text{ prime}} \ln\left(1 - \frac{1}{p^{s}}\right) =
      - \infty.
    \]
    Since for $0 < x < 0.6$ we have that $\ln(1-x) \geq -2x$ we get
    \[
      \lim_{s \to 1^+}
      - \sum_{p \text{ prime}} \frac{1}{2 p^s} \le
      \lim_{s \to 1^+}
      \sum_{p \text{ prime}} \ln\left(1 - \frac{1}{p^{s}}\right) =
      - \infty.
    \]
    Which proves that
    \[
      \sum_{p \text{ prime}} \frac{1}{p} = \infty,
    \]
    and completes the proof.
  \end{proof}

  \begin{definition}
    Let $(\Omega, \mathcal F, \mathbf P)$ be a probability space,
    and let $X \colon \Omega \to \R$ be a random variable.
    We say that $X$ is a continuous random variable if $F_X$ is a
    continuous function.
  \end{definition}
  \begin{remark}
    If $X$ is a continuous random variable then for any $a \in \R$
    \[
      \mathbf P(a) = 
      \lim_{n \to \infty}\left((a - 1/n, a]\right) =
      \lim_{n \to \infty} F_X(a) - F_X(a - 1/n) =
      0.
    \]
  \end{remark}
  
  Continuous random variables can get very weird, and in this course we
  will only discuss a very specific subset of random variables.

  \begin{definition}
    A random variable $X$ is called absolutely continuous if exists an
    integrable function $f_X \colon \R \to [0,\infty)$ such that for any
    $a \in \R$
    \[
      F_X(a) = \int_{-\infty}^{a} f_X(y)\,dy.
    \]
    In this case, we call $f_X$ the probability density function of $X$,
    or PDF for short.
  \end{definition}
  
  A couple of good points to notice are
  \begin{enumerate}
    \item From \autoref{thm:FcharacterizesP} we know that $F$ characterizes $P$,
    which means that we can use $f_X$ to calculate the probability of any
    event. For example let $A \subset \mathfrak B$ then
    \[
      P_X(A) = \int_{A} f_X(y)\,dy,
    \]
    but proving this equality is beyond the scope of these notes.
    \item We always know that
    \[
      1 = \mathbf P_X(\R) = \int_{-\infty}^{\infty} f_X(y)\,dy.
    \]
  \end{enumerate}

  \begin{example}
    Let $X$ be an absolutely continuous random variable with a probability
    density function $f$ defined as such
    \[
      f_X(y) =
      \begin{cases}
        C(2y - y^2), &y \in [0,1] \\
        0, &\text{otherwise}
      \end{cases}.
    \]
    What is the value of $C$? What is the probability that $X > 1$?

    To calculate $C$ we can use the second fact we mentioned earlier
    \[
      1 =
      \int_{-\infty}^{\infty} f_X(y)\,dy =
      C \int_{0}^{2} 2y - y^2\,dy =
      C\left[y^2 - \frac{y^3}{3}\right]\biggr\vert_{0}^{2} =
      \frac{4}{3} C,
    \]
    which implies that $C = \frac{3}{4}$. The probability that $X > 1$ is
    \[
      \mathbf P\left((1,\infty)\right) =
      \mathbf P\left((1,2)\right) =
      \frac{3}{4} \int_{1}^{2} 2y - y^2\,dy =
      \frac{1}{2}.
    \]
  \end{example}





\end{document}
